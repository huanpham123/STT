<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>STT Demo (Flask + speech_recognition) tr√™n Vercel</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
    }
    h1 {
      font-size: 24px;
      margin-bottom: 10px;
    }
    #controls {
      margin-bottom: 15px;
    }
    #record-btn {
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 4px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }
    #record-btn.recording {
      background-color: #dc3545;
    }
    #status {
      margin-left: 10px;
      font-weight: bold;
    }
    #transcript {
      margin-top: 20px;
      font-size: 18px;
      color: #333;
      white-space: pre-wrap;
    }
  </style>
</head>
<body>
  <h1>Demo STT (Flask + speech_recognition) tr√™n Vercel</h1>

  <div id="controls">
    <button id="record-btn">üé§ B·∫Øt ƒë·∫ßu ghi √¢m</button>
    <span id="status">Ch∆∞a ghi √¢m</span>
  </div>

  <div id="transcript">B·∫£n phi√™n √¢m s·∫Ω hi·ªán ·ªü ƒë√¢y ‚Ä¶</div>

  <script>
    // Thi·∫øt l·∫≠p bi·∫øn to√†n c·ª•c cho ghi √¢m v√† chuy·ªÉn WAV
    let audioContext;
    let microphoneStream;
    let scriptProcessor;
    let audioDataBuffer = [];
    const SAMPLE_RATE = 16000; // Deepgram / speech_recognition y√™u c·∫ßu 16kHz

    const recordBtn = document.getElementById("record-btn");
    const statusSpan = document.getElementById("status");
    const transcriptDiv = document.getElementById("transcript");
    let isRecording = false;

    recordBtn.addEventListener("click", () => {
      if (!isRecording) {
        startRecording();
      } else {
        stopRecording();
      }
    });

    async function startRecording() {
      try {
        // Y√™u c·∫ßu quy·ªÅn truy c·∫≠p microphone
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // T·∫°o AudioContext v·ªõi sample rate m·∫∑c ƒë·ªãnh (kh√¥ng nh·∫•t thi·∫øt 16kHz)
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        microphoneStream = audioContext.createMediaStreamSource(stream);

        // S·ª≠ d·ª•ng ScriptProcessorNode ƒë·ªÉ l·∫•y t√≠n hi·ªáu PCM
        // bufferSize: 4096 sample, channel count = 1 (mono)
        scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
        microphoneStream.connect(scriptProcessor);
        scriptProcessor.connect(audioContext.destination);

        audioDataBuffer = [];

        scriptProcessor.onaudioprocess = event => {
          // L·∫•y d·ªØ li·ªáu Float32Array (k√™nh mono)
          const inputBuffer = event.inputBuffer.getChannelData(0);
          // Chuy·ªÉn t·ª´ Float32 [-1..1] sang PCM16 (Int16)
          const downsampledBuffer = downsampleBuffer(inputBuffer, audioContext.sampleRate, SAMPLE_RATE);
          if (downsampledBuffer) {
            audioDataBuffer.push(downsampledBuffer);
          }
        };

        isRecording = true;
        recordBtn.textContent = "‚ñ† D·ª´ng ghi √¢m";
        recordBtn.classList.add("recording");
        statusSpan.textContent = "ƒêang ghi √¢m...";
        transcriptDiv.textContent = "";
      } catch (err) {
        console.error("Kh√¥ng th·ªÉ truy c·∫≠p microphone:", err);
        alert("Kh√¥ng th·ªÉ truy c·∫≠p microphone: " + err);
      }
    }

    function stopRecording() {
      // Ng·∫Øt k·∫øt n·ªëi microphone v√† ScriptProcessor
      scriptProcessor.disconnect();
      microphoneStream.disconnect();
      audioContext.close();

      isRecording = false;
      recordBtn.textContent = "üé§ B·∫Øt ƒë·∫ßu ghi √¢m";
      recordBtn.classList.remove("recording");
      statusSpan.textContent = "ƒêang x·ª≠ l√Ω‚Ä¶";

      // Gh√©p t·∫•t c·∫£ m·∫£ng Int16Array th√†nh m·ªôt Blob WAV
      const wavBlob = encodeWAV(audioDataBuffer, SAMPLE_RATE);
      sendToServer(wavBlob);
    }

    // H√†m downsample Float32Array (sampleRate ‚Üí targetRate), tr·∫£ v·ªÅ Int16Array
    function downsampleBuffer(buffer, inputRate, outputRate) {
      if (outputRate === inputRate) {
        // Chuy·ªÉn tr·ª±c ti·∫øp Float32 [-1..1] sang Int16
        const int16 = new Int16Array(buffer.length);
        for (let i = 0; i < buffer.length; i++) {
          const s = Math.max(-1, Math.min(1, buffer[i]));
          int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        return int16;
      }
      const sampleRateRatio = inputRate / outputRate;
      const newLength = Math.round(buffer.length / sampleRateRatio);
      const result = new Int16Array(newLength);
      let offsetResult = 0;
      let offsetBuffer = 0;
      while (offsetResult < newLength) {
        const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
        let sum = 0, count = 0;
        for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
          sum += buffer[i];
          count++;
        }
        const avg = sum / count;
        result[offsetResult] = avg < 0 ? avg * 0x8000 : avg * 0x7FFF;
        offsetResult++;
        offsetBuffer = nextOffsetBuffer;
      }
      return result;
    }

    // H√†m t·∫°o Blob WAV t·ª´ m·∫£ng Int16Array[]
    function encodeWAV(buffers, sampleRate) {
      // T√≠nh t·ªïng length
      let totalSamples = 0;
      for (let i = 0; i < buffers.length; i++) {
        totalSamples += buffers[i].length;
      }
      const bytesPerSample = 2;
      const blockAlign = 1 * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = totalSamples * bytesPerSample;
      const buffer = new ArrayBuffer(44 + dataSize);
      const view = new DataView(buffer);

      /* RIFF identifier */
      writeString(view, 0, "RIFF");
      /* file length */
      view.setUint32(4, 36 + dataSize, true);
      /* RIFF type */
      writeString(view, 8, "WAVE");
      /* format chunk identifier */
      writeString(view, 12, "fmt ");
      /* format chunk length */
      view.setUint32(16, 16, true);
      /* sample format (raw) */
      view.setUint16(20, 1, true);
      /* channel count */
      view.setUint16(22, 1, true); // mono
      /* sample rate */
      view.setUint32(24, sampleRate, true);
      /* byte rate (sampleRate * blockAlign) */
      view.setUint32(28, byteRate, true);
      /* block align (channelCount * bytesPerSample) */
      view.setUint16(32, blockAlign, true);
      /* bits per sample */
      view.setUint16(34, 16, true);
      /* data chunk identifier */
      writeString(view, 36, "data");
      /* data chunk length */
      view.setUint32(40, dataSize, true);

      // Ghi PCM samples
      let offset = 44;
      for (let i = 0; i < buffers.length; i++) {
        const buffer16 = buffers[i];
        for (let j = 0; j < buffer16.length; j++, offset += 2) {
          view.setInt16(offset, buffer16[j], true);
        }
      }

      return new Blob([view], { type: "audio/wav" });
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    function sendToServer(wavBlob) {
      const fd = new FormData();
      fd.append("audio_data", wavBlob, "recording.wav");

      fetch("/transcribe", {
        method: "POST",
        body: fd
      })
      .then(response => response.json())
      .then(data => {
        if (data.transcript !== undefined) {
          transcriptDiv.textContent = data.transcript;
          statusSpan.textContent = "Ho√†n t·∫•t.";
        } else if (data.error) {
          transcriptDiv.textContent = "L·ªói: " + data.error;
          statusSpan.textContent = "L·ªói.";
        } else {
          transcriptDiv.textContent = "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c transcript.";
          statusSpan.textContent = "Xong.";
        }
      })
      .catch(err => {
        console.error("L·ªói g·ª≠i l√™n server:", err);
        transcriptDiv.textContent = "L·ªói khi g·ªçi /transcribe: " + err;
        statusSpan.textContent = "L·ªói.";
      });
    }
  </script>
</body>
</html>
