<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Streaming STT v·ªõi Web Speech API</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
    }
    #controls {
      margin-bottom: 15px;
    }
    #record-btn {
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 4px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }
    #record-btn.recording {
      background-color: #dc3545;
    }
    #status {
      margin-left: 10px;
      font-weight: bold;
    }
    #transcript {
      margin-top: 20px;
      font-size: 18px;
      color: #333;
      white-space: pre-wrap;
    }
  </style>
</head>
<body>
  <h1>Streaming STT (Web Speech API)</h1>

  <div id="controls">
    <button id="record-btn">üé§ B·∫Øt ƒë·∫ßu n√≥i</button>
    <span id="status">Ch∆∞a b·∫Øt ƒë·∫ßu</span>
  </div>

  <div id="transcript">K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y ‚Ä¶</div>

  <script>
    // 1. Ki·ªÉm tra h·ªó tr·ª£ SpeechRecognition
    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!window.SpeechRecognition) {
      alert("Tr√¨nh duy·ªát c·ªßa b·∫°n kh√¥ng h·ªó tr·ª£ Web Speech API. Vui l√≤ng d√πng Chrome/Edge m·ªõi nh·∫•t.");
      throw new Error("Web Speech API not supported");
    }

    const recordBtn = document.getElementById("record-btn");
    const statusSpan = document.getElementById("status");
    const transcriptDiv = document.getElementById("transcript");

    let recognition;
    let isRecording = false;

    function initRecognition() {
      recognition = new window.SpeechRecognition();
      recognition.continuous = true;            // Gi·ªØ k·∫øt n·ªëi li√™n t·ª•c
      recognition.interimResults = true;        // Nh·∫≠n k·∫øt qu·∫£ ‚Äúinterim‚Äù khi ng∆∞·ªùi d√πng v·∫´n ƒëang n√≥i
      recognition.lang = "vi-VN";               // Thi·∫øt l·∫≠p ng√¥n ng·ªØ ti·∫øng Vi·ªát

      recognition.onstart = () => {
        statusSpan.textContent = "ƒêang nghe...";
      };

      recognition.onerror = (event) => {
        console.error("Recognition error:", event.error);
        statusSpan.textContent = "L·ªói: " + event.error;
      };

      recognition.onend = () => {
        // Khi ng∆∞·ªùi d√πng ·∫•n d·ª´ng ho·∫∑c k·∫øt n·ªëi b·ªã ng·∫Øt
        if (isRecording) {
          // C√≥ th·ªÉ t·ª± ƒë·ªông kh·ªüi ƒë·ªông l·∫°i n·∫øu mu·ªën ‚Äúli√™n t·ª•c kh√¥ng ng·ª´ng‚Äù
          // recognition.start();
          statusSpan.textContent = "ƒê√£ d·ª´ng.";
          isRecording = false;
          recordBtn.textContent = "üé§ B·∫Øt ƒë·∫ßu n√≥i";
          recordBtn.classList.remove("recording");
        }
      };

      recognition.onresult = (event) => {
        // event.results l√† ƒë·ªëi t∆∞·ª£ng SpeechRecognitionResultList
        let interim = "";
        let finalText = "";
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalText += transcript + " ";
          } else {
            interim += transcript;
          }
        }
        // Hi·ªÉn th·ªã k·∫øt qu·∫£ t·∫°m th·ªùi (interim) + k·∫øt qu·∫£ cu·ªëi (final)
        transcriptDiv.textContent = finalText + "\n" + "%c[" + interim + "]"; // interim m√†u kh√°c n·∫øu mu·ªën
      };
    }

    recordBtn.addEventListener("click", () => {
      if (!isRecording) {
        // B·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng
        initRecognition();
        recognition.start();
        isRecording = true;
        recordBtn.textContent = "‚ñ† D·ª´ng n√≥i";
        recordBtn.classList.add("recording");
      } else {
        // D·ª´ng nh·∫≠n d·∫°ng
        recognition.stop();
        // recognition.onend s·∫Ω ƒë∆∞·ª£c g·ªçi, v√† c·∫≠p nh·∫≠t tr·∫°ng th√°i
      }
    });
  </script>
</body>
</html>
